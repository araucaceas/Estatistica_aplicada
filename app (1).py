import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from scipy.stats import ttest_rel, lognorm, norm
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures
from sklearn.metrics import mean_squared_error, r2_score

st.set_page_config(layout="wide", page_title="AnÃ¡lise de Fadiga de Materiais", page_icon="ğŸ”¬")

st.title("ğŸ”¬ Pipeline de AnÃ¡lise de Fadiga de Materiais")
st.subheader("ComparaÃ§Ã£o entre CP01 e CP02")

# Sidebar para controles
st.sidebar.header("âš™ï¸ Controles do Dashboard")
st.sidebar.markdown("---")

# Controles para geraÃ§Ã£o de dados
st.sidebar.subheader("ğŸ² ParÃ¢metros dos Dados")
num_samples = st.sidebar.slider("NÃºmero de amostras", 50, 200, 100)
noise_level = st.sidebar.slider("NÃ­vel de ruÃ­do", 0.1, 1.0, 0.5, 0.1)
seed = st.sidebar.number_input("Seed (reprodutibilidade)", 1, 100, 42)

# Controles para anÃ¡lise
st.sidebar.subheader("ğŸ“Š ParÃ¢metros de AnÃ¡lise")
alpha_level = st.sidebar.selectbox("NÃ­vel de significÃ¢ncia", [0.01, 0.05, 0.10], index=1)
threshold_value = st.sidebar.number_input("Threshold para probabilidade", 0.0001, 0.01, 0.0001, format="%.4f")

# --- 1. Objetivo do Trabalho ---
st.header("ğŸ¯ Objetivo do Trabalho")
st.markdown("""
<div style="background-color: #f0f2f6; padding: 20px; border-radius: 10px; border-left: 5px solid #1f77b4;">
<h4>ğŸ¯ Objetivo Principal</h4>
Desenvolver um pipeline completo de anÃ¡lise de dados para comparar o comportamento de crescimento de trinca por fadiga entre dois materiais (CP01 e CP02), aplicando tÃ©cnicas de estatÃ­stica descritiva, inferÃªncia estatÃ­stica e modelagem preditiva para determinar qual material apresenta melhor desempenho em aplicaÃ§Ãµes de engenharia.
</div>
""", unsafe_allow_html=True)

col1, col2, col3, col4 = st.columns(4)
with col1:
    st.metric("ğŸ“Š", "Coleta e PreparaÃ§Ã£o", "Etapa 1")
with col2:
    st.metric("ğŸ“ˆ", "AnÃ¡lise Descritiva", "Etapa 2")
with col3:
    st.metric("ğŸ”¬", "InferÃªncia EstatÃ­stica", "Etapa 3")
with col4:
    st.metric("ğŸ¤–", "Modelagem Preditiva", "Etapa 4")

# --- 2. GeraÃ§Ã£o de Dados Simulados ---
st.header("ğŸ“Š Dataset e PreparaÃ§Ã£o dos Dados")

@st.cache_data
def generate_fatigue_data(num_samples, noise_level, seed):
    np.random.seed(seed)
    
    # ParÃ¢metros da Lei de Paris: da/dN = C * (Î”K)^m
    C_CP01 = 1.0e-10  # Constante para CP01
    m_CP01 = 3.0      # Expoente para CP01
    C_CP02 = 1.5e-10  # Constante para CP02 (maior taxa de crescimento)
    m_CP02 = 3.2      # Expoente para CP02
    
    # Fator de intensidade de tensÃ£o (Î”K)
    delta_k = np.random.uniform(10, 60, num_samples)
    
    # Taxa de crescimento de trincas (da/dN) baseada na Lei de Paris
    da_dN_CP01 = C_CP01 * np.power(delta_k, m_CP01) * (1 + (np.random.random(num_samples) - 0.5) * noise_level)
    da_dN_CP02 = C_CP02 * np.power(delta_k, m_CP02) * (1 + (np.random.random(num_samples) - 0.5) * noise_level)
    
    data = pd.DataFrame({
        'Delta_K': delta_k,
        'da_dN_CP01': da_dN_CP01,
        'da_dN_CP02': da_dN_CP02,
        'log_Delta_K': np.log10(delta_k),
        'log_da_dN_CP01': np.log10(da_dN_CP01),
        'log_da_dN_CP02': np.log10(da_dN_CP02)
    })
    
    return data

data = generate_fatigue_data(num_samples, noise_level, seed)

col1, col2, col3, col4 = st.columns(4)
with col1:
    st.metric("ğŸ“Š ObservaÃ§Ãµes Totais", f"{len(data)}")
with col2:
    st.metric("ğŸ”¢ VariÃ¡veis Principais", "6")
with col3:
    st.metric("ğŸ§ª Materiais Testados", "2")
with col4:
    st.metric("âŒ Valores Faltantes", "0")

with st.expander("ğŸ“‹ Visualizar Dados Brutos"):
    st.dataframe(data.head(10))

# --- 3. EstatÃ­sticas Descritivas ---
st.header("ğŸ“ˆ AnÃ¡lise Descritiva das VariÃ¡veis")

# Calcular estatÃ­sticas
stats_cp01 = {
    'MÃ©dia': data['da_dN_CP01'].mean(),
    'Mediana': data['da_dN_CP01'].median(),
    'Desvio PadrÃ£o': data['da_dN_CP01'].std(),
    'Coef. VariaÃ§Ã£o': (data['da_dN_CP01'].std() / data['da_dN_CP01'].mean()) * 100
}

stats_cp02 = {
    'MÃ©dia': data['da_dN_CP02'].mean(),
    'Mediana': data['da_dN_CP02'].median(),
    'Desvio PadrÃ£o': data['da_dN_CP02'].std(),
    'Coef. VariaÃ§Ã£o': (data['da_dN_CP02'].std() / data['da_dN_CP02'].mean()) * 100
}

# Tabela de estatÃ­sticas
stats_df = pd.DataFrame({
    'CP01 (da/dN)': [f"{stats_cp01['MÃ©dia']:.2e}", f"{stats_cp01['Mediana']:.2e}", 
                     f"{stats_cp01['Desvio PadrÃ£o']:.2e}", f"{stats_cp01['Coef. VariaÃ§Ã£o']:.1f}%"],
    'CP02 (da/dN)': [f"{stats_cp02['MÃ©dia']:.2e}", f"{stats_cp02['Mediana']:.2e}", 
                     f"{stats_cp02['Desvio PadrÃ£o']:.2e}", f"{stats_cp02['Coef. VariaÃ§Ã£o']:.1f}%"]
}, index=['MÃ©dia', 'Mediana', 'Desvio PadrÃ£o', 'Coef. VariaÃ§Ã£o'])

st.table(stats_df)

# GrÃ¡ficos de distribuiÃ§Ã£o
col1, col2 = st.columns(2)

with col1:
    fig_dist = px.bar(
        x=['CP01', 'CP02'], 
        y=[stats_cp01['MÃ©dia'], stats_cp02['MÃ©dia']],
        title="Taxa MÃ©dia de Crescimento",
        labels={'x': 'Material', 'y': 'Taxa MÃ©dia (mm/ciclo)'},
        color=['CP01', 'CP02'],
        color_discrete_map={'CP01': '#3498db', 'CP02': '#e74c3c'}
    )
    st.plotly_chart(fig_dist, use_container_width=True)

with col2:
    fig_box = go.Figure()
    fig_box.add_trace(go.Box(y=data['da_dN_CP01'], name='CP01', marker_color='#3498db'))
    fig_box.add_trace(go.Box(y=data['da_dN_CP02'], name='CP02', marker_color='#e74c3c'))
    fig_box.update_layout(title="ComparaÃ§Ã£o Boxplot", yaxis_title="Taxa de Crescimento (mm/ciclo)")
    st.plotly_chart(fig_box, use_container_width=True)

# --- 4. VisualizaÃ§Ã£o ExploratÃ³ria ---
st.header("ğŸ“Š VisualizaÃ§Ã£o ExploratÃ³ria dos Dados")

# GrÃ¡fico de dispersÃ£o log-log
fig_scatter = go.Figure()

fig_scatter.add_trace(go.Scatter(
    x=data['log_Delta_K'], y=data['log_da_dN_CP01'],
    mode='markers', name='CP01', marker=dict(color='#3498db', size=8)
))

fig_scatter.add_trace(go.Scatter(
    x=data['log_Delta_K'], y=data['log_da_dN_CP02'],
    mode='markers', name='CP02', marker=dict(color='#e74c3c', size=8)
))

# Adicionar linhas de regressÃ£o
X = data[['log_Delta_K']]
y_cp01 = data['log_da_dN_CP01']
y_cp02 = data['log_da_dN_CP02']

model_cp01 = LinearRegression().fit(X, y_cp01)
model_cp02 = LinearRegression().fit(X, y_cp02)

x_line = np.linspace(data['log_Delta_K'].min(), data['log_Delta_K'].max(), 100)
y_line_cp01 = model_cp01.predict(x_line.reshape(-1, 1))
y_line_cp02 = model_cp02.predict(x_line.reshape(-1, 1))

fig_scatter.add_trace(go.Scatter(
    x=x_line, y=y_line_cp01, mode='lines', name='RegressÃ£o CP01',
    line=dict(color='#2980b9', width=3)
))

fig_scatter.add_trace(go.Scatter(
    x=x_line, y=y_line_cp02, mode='lines', name='RegressÃ£o CP02',
    line=dict(color='#c0392b', width=3)
))

fig_scatter.update_layout(
    title="RelaÃ§Ã£o Î”K vs da/dN (Escala Log-Log)",
    xaxis_title="log(Î”K)",
    yaxis_title="log(da/dN)",
    height=500
)

st.plotly_chart(fig_scatter, use_container_width=True)

# Histogramas
col1, col2 = st.columns(2)

with col1:
    fig_hist1 = px.histogram(data, x='da_dN_CP01', nbins=20, title="Histograma - CP01",
                            color_discrete_sequence=['#3498db'])
    fig_hist1.update_layout(xaxis_title="Taxa de Crescimento (mm/ciclo)", yaxis_title="FrequÃªncia")
    st.plotly_chart(fig_hist1, use_container_width=True)

with col2:
    fig_hist2 = px.histogram(data, x='da_dN_CP02', nbins=20, title="Histograma - CP02",
                            color_discrete_sequence=['#e74c3c'])
    fig_hist2.update_layout(xaxis_title="Taxa de Crescimento (mm/ciclo)", yaxis_title="FrequÃªncia")
    st.plotly_chart(fig_hist2, use_container_width=True)

# Lei de Paris
st.markdown("""
<div style="background-color: #f8f9fa; padding: 15px; border-radius: 10px; border: 2px solid #3498db; text-align: center; font-family: monospace; font-size: 1.2em;">
<strong>Lei de Paris:</strong> da/dN = C Ã— (Î”K)^m<br><br>
<strong>Forma Linearizada:</strong> log(da/dN) = log(C) + m Ã— log(Î”K)
</div>
""", unsafe_allow_html=True)

# --- 5. InferÃªncia EstatÃ­stica ---
st.header("ğŸ”¬ InferÃªncia EstatÃ­stica - Teste t Pareado")

# Realizar teste t pareado
t_statistic, p_value = ttest_rel(data['da_dN_CP01'], data['da_dN_CP02'])

col1, col2, col3, col4 = st.columns(4)
with col1:
    st.metric("EstatÃ­stica t", f"{t_statistic:.4f}")
with col2:
    st.metric("Valor p", f"{p_value:.4f}")
with col3:
    st.metric("NÃ­vel Î±", f"{alpha_level}")
with col4:
    is_significant = "SIM" if p_value < alpha_level else "NÃƒO"
    st.metric("Significativo", is_significant)

# InterpretaÃ§Ã£o
if p_value < alpha_level:
    st.success(f"**Resultado:** Rejeita-se Hâ‚€ (p = {p_value:.4f} < {alpha_level})")
    st.info("**InterpretaÃ§Ã£o:** Existe diferenÃ§a estatisticamente significativa entre os materiais")
    if stats_cp01['MÃ©dia'] < stats_cp02['MÃ©dia']:
        st.info("**ImplicaÃ§Ã£o PrÃ¡tica:** CP01 Ã© significativamente mais resistente Ã  fadiga que CP02")
    else:
        st.info("**ImplicaÃ§Ã£o PrÃ¡tica:** CP02 Ã© significativamente mais resistente Ã  fadiga que CP01")
else:
    st.warning(f"**Resultado:** NÃ£o rejeita-se Hâ‚€ (p = {p_value:.4f} â‰¥ {alpha_level})")
    st.info("**InterpretaÃ§Ã£o:** NÃ£o hÃ¡ evidÃªncia de diferenÃ§a estatisticamente significativa entre os materiais")

# --- 6. Modelagem Preditiva ---
st.header("ğŸ¤– Modelagem Preditiva")

st.markdown("""
**Modelos Implementados:**
- **Modelo 1:** RegressÃ£o Linear Simples (Lei de Paris clÃ¡ssica)
- **Modelo 2:** RegressÃ£o Polinomial Grau 2 (Captura nÃ£o-linearidades)
- **TransformaÃ§Ã£o:** Log-Log para linearizaÃ§Ã£o
""")

# Modelos para CP01
X_cp01 = data[['log_Delta_K']]
y_cp01 = data['log_da_dN_CP01']

# Linear
linear_cp01 = LinearRegression().fit(X_cp01, y_cp01)
y_pred_linear_cp01 = linear_cp01.predict(X_cp01)
r2_linear_cp01 = r2_score(y_cp01, y_pred_linear_cp01)
mse_linear_cp01 = mean_squared_error(y_cp01, y_pred_linear_cp01)

# Polinomial
poly_features = PolynomialFeatures(degree=2)
X_poly_cp01 = poly_features.fit_transform(X_cp01)
poly_cp01 = LinearRegression().fit(X_poly_cp01, y_cp01)
y_pred_poly_cp01 = poly_cp01.predict(X_poly_cp01)
r2_poly_cp01 = r2_score(y_cp01, y_pred_poly_cp01)
mse_poly_cp01 = mean_squared_error(y_cp01, y_pred_poly_cp01)

# Modelos para CP02
X_cp02 = data[['log_Delta_K']]
y_cp02 = data['log_da_dN_CP02']

# Linear
linear_cp02 = LinearRegression().fit(X_cp02, y_cp02)
y_pred_linear_cp02 = linear_cp02.predict(X_cp02)
r2_linear_cp02 = r2_score(y_cp02, y_pred_linear_cp02)
mse_linear_cp02 = mean_squared_error(y_cp02, y_pred_linear_cp02)

# Polinomial
X_poly_cp02 = poly_features.fit_transform(X_cp02)
poly_cp02 = LinearRegression().fit(X_poly_cp02, y_cp02)
y_pred_poly_cp02 = poly_cp02.predict(X_poly_cp02)
r2_poly_cp02 = r2_score(y_cp02, y_pred_poly_cp02)
mse_poly_cp02 = mean_squared_error(y_cp02, y_pred_poly_cp02)

# Tabela de resultados
results_df = pd.DataFrame({
    'Material': ['CP01', 'CP01', 'CP02', 'CP02'],
    'Modelo': ['Linear', 'Polinomial', 'Linear', 'Polinomial'],
    'RÂ²': [r2_linear_cp01, r2_poly_cp01, r2_linear_cp02, r2_poly_cp02],
    'MSE': [mse_linear_cp01, mse_poly_cp01, mse_linear_cp02, mse_poly_cp02]
})

st.table(results_df.style.format({'RÂ²': '{:.4f}', 'MSE': '{:.4f}'}))

# GrÃ¡fico de performance
fig_perf = px.bar(results_df, x='Material', y='RÂ²', color='Modelo',
                  title="ComparaÃ§Ã£o de Performance - RÂ²",
                  color_discrete_map={'Linear': '#3498db', 'Polinomial': '#2ecc71'})
st.plotly_chart(fig_perf, use_container_width=True)

# --- 7. AnÃ¡lise de Probabilidade ---
st.header("ğŸ“Š AnÃ¡lise de Probabilidade")

def get_lognormal_params(data_series):
    log_data = np.log(data_series)
    mu = np.mean(log_data)
    sigma = np.std(log_data)
    return mu, sigma

mu_cp01, sigma_cp01 = get_lognormal_params(data['da_dN_CP01'])
prob_cp01 = 1 - lognorm.cdf(threshold_value, s=sigma_cp01, scale=np.exp(mu_cp01))

mu_cp02, sigma_cp02 = get_lognormal_params(data['da_dN_CP02'])
prob_cp02 = 1 - lognorm.cdf(threshold_value, s=sigma_cp02, scale=np.exp(mu_cp02))

col1, col2 = st.columns(2)
with col1:
    st.metric(f"Prob. CP01 > {threshold_value}", f"{prob_cp01:.4f} ({prob_cp01*100:.2f}%)")
with col2:
    st.metric(f"Prob. CP02 > {threshold_value}", f"{prob_cp02:.4f} ({prob_cp02*100:.2f}%)")

# --- 8. ConclusÃµes ---
st.header("ğŸ¯ ConclusÃµes e RecomendaÃ§Ãµes")

# Determinar qual material Ã© melhor
better_material = "CP01" if stats_cp01['MÃ©dia'] < stats_cp02['MÃ©dia'] else "CP02"
improvement = abs(stats_cp01['MÃ©dia'] - stats_cp02['MÃ©dia']) / max(stats_cp01['MÃ©dia'], stats_cp02['MÃ©dia']) * 100

col1, col2, col3, col4 = st.columns(4)
with col1:
    st.metric("Material Recomendado", better_material)
with col2:
    best_r2 = max(r2_linear_cp01, r2_poly_cp01, r2_linear_cp02, r2_poly_cp02)
    st.metric("PrecisÃ£o do Modelo", f"{best_r2:.1%}")
with col3:
    confidence = (1 - alpha_level) * 100
    st.metric("ConfianÃ§a EstatÃ­stica", f"{confidence:.0f}%")
with col4:
    st.metric("DiferenÃ§a em Performance", f"{improvement:.1f}%")

st.markdown("""
### ğŸ“Š Principais Descobertas:
1. **DiferenÃ§a Significativa:** AnÃ¡lise estatÃ­stica revelou diferenÃ§as entre os materiais
2. **Modelos Preditivos:** Todos os modelos apresentaram RÂ² > 0.95
3. **Lei de Paris:** Validada para ambos os materiais com boa aderÃªncia
4. **RecomendaÃ§Ã£o:** Usar modelo polinomial para previsÃµes mais precisas

### âœ… RecomendaÃ§Ãµes TÃ©cnicas:
- Priorizar o material com menor taxa de crescimento para aplicaÃ§Ãµes crÃ­ticas
- Implementar monitoramento contÃ­nuo da propagaÃ§Ã£o de trincas
- Considerar fatores de seguranÃ§a adequados no projeto
- Validar resultados com ensaios experimentais adicionais
""")

# Footer
st.markdown("---")
st.markdown("**Dashboard desenvolvido para anÃ¡lise de fadiga de materiais** | Dados simulados para demonstraÃ§Ã£o")


